.. Poke-env documentation master file, created by
   sphinx-quickstart on Sat Aug 10 13:11:15 2019.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Poke-env: A python interface for training Reinforcement Learning pokemon bots
#############################################################################

This project aims at providing a Python environment for interacting in `pokemon showdown <https://pokemonshowdown.com/>`__ battles, with reinforcement learning in mind. Welcome to its documentation!

Getting started
***************

Installing poke-env
===================

Installing a showdown server
============================

Creating a first agent
======================

Configuring showdown players
****************************

Users without authentication
============================

Users with authentication
=========================

This project requires python >= 3.6 and a `Pokemon Showdown <https://github.com/Zarel/Pokemon-Showdown>`__ server.

Examples
********

.. toctree::
   :maxdepth: 5

   examples

Documentation
*************

.. toctree::
   :maxdepth: 5

   poke-env

Other
*****

Acknowledgements
================

This project is a follow-up of a group project from an artifical intelligence class at `Ecole Polytechnique <https://www.polytechnique.edu/>`__.

You can find the original repository `here <https://github.com/hsahovic/inf581-project>`__. It is partially inspired by the `showdown-battle-bot project <https://github.com/Synedh/showdown-battle-bot>`__. Of course, none of these would have been possible without `Pokemon Showdown <https://github.com/Zarel/Pokemon-Showdown>`__.

Data
====

Data files are adapted version of the :samp:`js` data files of `Pokemon Showdown <https://github.com/Zarel/Pokemon-Showdown>`__.

License
=======

This project and its documentation are released under the `MIT License <https://opensource.org/licenses/MIT>`__.
